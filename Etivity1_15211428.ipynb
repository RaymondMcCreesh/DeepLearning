{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZTZKxJcH-2y"
      },
      "source": [
        "# E-tivity 1 (23/01/23 - 05/02/23)\n",
        "\n",
        "* Your Name : Raymond Mc Creesh\n",
        "\n",
        "* Your Student ID : 15211428"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOmL579kH-29"
      },
      "source": [
        "## Anomaly Detection\n",
        "\n",
        "### Context\n",
        "We have a mystery dataset. There are 9 explanatory variables and one response variable. The response variable is the last column and indicates if the sample is anomalous (=1, valid =0). The dataset is provided \"data.csv\". \n",
        "\n",
        "Of course in this case we could use supervised learning to generate a model and detect anomalies in new data. However the focus is on autoencoders, anomaly detection is just one of the potential uses for autoencoders.\n",
        "\n",
        "So we are going to pretend that we do not know which data are anomalous but we do know that the anomaly rate is small. Use an autoencoder to detect anomalies in the data. The correctness of the model can of course be checked."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# Load the module we need\n",
        "# Note that we are import the Keras backend, which is assumed to be Tensorflow\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, MaxPooling2D\n",
        "from tensorflow.keras.layers import UpSampling2D, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.losses import mean_squared_error, binary_crossentropy, mse, KLDivergence\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "c20xDJgJIz2-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-oN9QA8H-2_"
      },
      "source": [
        "### Guidelines\n",
        "\n",
        "The e-tivity is split into four tasks. The first three are \"group\" excersises, in that you post the solutions to Tasks 1-3 to a site. This will allow the members of your group to send you feedback (via the forums) so you can improve your submission. The final task is an individual task and together with the other tasks, should be uploaded to Sulis but not to gitlab. \n",
        "\n",
        "Marks will be deducted if task 4 is posted to gitlab in contravention of instructions. Also if the the final submission is not a single notebook with tasks 1-4 and with correct identification or filename.\n",
        "\n",
        "Grading guidelines: the scores for each task are additive, max 20. Weight [5/7]\n",
        "\n",
        "**Task 1 [0-6]**: perform and explain the steps taken in data pre-processing for this unsupervised learning model.\n",
        "\n",
        "**Task 2 [0-4]**: correctly train model to convergence with a suitable topology and 2 encoded variables.\n",
        "\n",
        "**Task 3 [0-4]**: select and explain choice of threshold for determining the anomalous data.\n",
        "\n",
        "**Task 4 [0-6]**: implement a suitable VAE with correct testing and not uploaded to gitlab, in contravention of the instructions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwRsvI0dH-3B"
      },
      "source": [
        "## Problem\n",
        "\n",
        "If you train even a modest feed forward network via supervised learning you can get extremely good recall and precision, despite the unbalanced dataset. However in this e-tivity you will determining the anomalies by using an autoencoder. That is you will **not** be using the Anom flag to guide the training.\n",
        "\n",
        "The mystery dataset is available from the Sulis site, download the csv file and use it as the input data.\n",
        "\n",
        "### Tasks 1-3 (complete by Monday 30/01/23)\n",
        "\n",
        "These tasks are to be completed and uploaded to GitLab on which the other group members can comment. The forum activity will form part of the overall mark for the e-tivity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkrz66V5H-3C"
      },
      "source": [
        "**Task 1: data preprocessing**\n",
        "\n",
        "Explain any preprocessing steps you take and also how you have selected the training and test sets. Remember we do not know which samples are anomalous only that there are a small number of them compared to the total sample size.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data.csv\")"
      ],
      "metadata": {
        "id": "L9QziKUDIwAP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlKfZ9s4JdRh",
        "outputId": "3778436e-1a39-4ad4-f782-68cf76954933"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 49097 entries, 0 to 49096\n",
            "Data columns (total 10 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   V1      49097 non-null  int64\n",
            " 1   V2      49097 non-null  int64\n",
            " 2   V3      49097 non-null  int64\n",
            " 3   V4      49097 non-null  int64\n",
            " 4   V5      49097 non-null  int64\n",
            " 5   V6      49097 non-null  int64\n",
            " 6   V7      49097 non-null  int64\n",
            " 7   V8      49097 non-null  int64\n",
            " 8   V9      49097 non-null  int64\n",
            " 9   Anom    49097 non-null  int64\n",
            "dtypes: int64(10)\n",
            "memory usage: 3.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "shbhH3rQKMsn",
        "outputId": "239e1a20-03e6-4932-bc2b-11606c625b13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 V1            V2            V3            V4            V5  \\\n",
              "count  49097.000000  49097.000000  49097.000000  49097.000000  49097.000000   \n",
              "mean      46.932399     -0.063955     85.123124      0.213231     36.871784   \n",
              "std       12.875159     84.674481      8.877517     37.579171     19.963113   \n",
              "min       27.000000  -4821.000000     21.000000  -3939.000000   -188.000000   \n",
              "25%       37.000000      0.000000     79.000000      0.000000     30.000000   \n",
              "50%       44.000000      0.000000     83.000000      0.000000     42.000000   \n",
              "75%       50.000000      0.000000     88.000000      0.000000     46.000000   \n",
              "max      126.000000   5075.000000    149.000000   3830.000000    436.000000   \n",
              "\n",
              "                 V6            V7            V8            V9          Anom  \n",
              "count  49097.000000  49097.000000  49097.000000  49097.000000  49097.000000  \n",
              "mean       2.160030     38.200725     48.288592     10.261930      0.071511  \n",
              "std      218.324964     13.446306     20.572064     23.751024      0.257680  \n",
              "min   -26739.000000    -48.000000   -353.000000   -356.000000      0.000000  \n",
              "25%       -4.000000     33.000000     35.000000      0.000000      0.000000  \n",
              "50%        0.000000     39.000000     41.000000      2.000000      0.000000  \n",
              "75%        5.000000     43.000000     55.000000      6.000000      0.000000  \n",
              "max    15164.000000    105.000000    270.000000    266.000000      1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2722261e-65f4-41fe-8620-d1e59d0eab90\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>Anom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>49097.000000</td>\n",
              "      <td>49097.000000</td>\n",
              "      <td>49097.000000</td>\n",
              "      <td>49097.000000</td>\n",
              "      <td>49097.000000</td>\n",
              "      <td>49097.000000</td>\n",
              "      <td>49097.000000</td>\n",
              "      <td>49097.000000</td>\n",
              "      <td>49097.000000</td>\n",
              "      <td>49097.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>46.932399</td>\n",
              "      <td>-0.063955</td>\n",
              "      <td>85.123124</td>\n",
              "      <td>0.213231</td>\n",
              "      <td>36.871784</td>\n",
              "      <td>2.160030</td>\n",
              "      <td>38.200725</td>\n",
              "      <td>48.288592</td>\n",
              "      <td>10.261930</td>\n",
              "      <td>0.071511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.875159</td>\n",
              "      <td>84.674481</td>\n",
              "      <td>8.877517</td>\n",
              "      <td>37.579171</td>\n",
              "      <td>19.963113</td>\n",
              "      <td>218.324964</td>\n",
              "      <td>13.446306</td>\n",
              "      <td>20.572064</td>\n",
              "      <td>23.751024</td>\n",
              "      <td>0.257680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>27.000000</td>\n",
              "      <td>-4821.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>-3939.000000</td>\n",
              "      <td>-188.000000</td>\n",
              "      <td>-26739.000000</td>\n",
              "      <td>-48.000000</td>\n",
              "      <td>-353.000000</td>\n",
              "      <td>-356.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>-4.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>44.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>126.000000</td>\n",
              "      <td>5075.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>3830.000000</td>\n",
              "      <td>436.000000</td>\n",
              "      <td>15164.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2722261e-65f4-41fe-8620-d1e59d0eab90')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2722261e-65f4-41fe-8620-d1e59d0eab90 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2722261e-65f4-41fe-8620-d1e59d0eab90');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79_CrbrcKY0m",
        "outputId": "d19260a1-cbc8-4eb8-d1b1-2b880ec38a77"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "V1      0\n",
              "V2      0\n",
              "V3      0\n",
              "V4      0\n",
              "V5      0\n",
              "V6      0\n",
              "V7      0\n",
              "V8      0\n",
              "V9      0\n",
              "Anom    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize the scaler\n",
        "# scaler = MinMaxScaler()\n",
        "\n",
        "# # Fit the scaler to the training data\n",
        "# scaler.fit(df)\n",
        "# df_scaled = scaler.transform(df)\n",
        "# #turn back to pandas dataframe\n",
        "# df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n",
        "df_scaled = (df - df.min())/(df.max() - df.min())"
      ],
      "metadata": {
        "id": "6_udrzykKftm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_scaled.drop(columns='Anom')\n",
        "Y = df_scaled['Anom']\n",
        " # Assign the features and labels\n",
        "# X = df_scaled[:, :-1]  # select all rows and all columns except the last one\n",
        "# Y = df_scaled[:, -1] \n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y,stratify=Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "RM1U4QKHMNvr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1vEPqsUjn5W",
        "outputId": "de4f71cc-206c-4c69-f916-c0c337ea4eca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39277, 9)\n",
            "(9820, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UELA6I9KH-3D"
      },
      "source": [
        "**Task 2: model generation and training**\n",
        "\n",
        "Generate a suitable autoencoder model, the only restriction is that there should be only 2 latent variables. Train the model to a satistifactory result. Be aware that it will be much harder to achieve the sort of result you can get from a supervised learning model. \n",
        "\n",
        "**Hint**: it should not take longer than a 1000 epochs to train. However it may be difficult to train. Use different optimizers, topologies and/or weight initialisations to get convergence. Remember that achieving a perfect error means that the model will also be good at reconstructing anomalies. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the input layer\n",
        "input_data = Input(shape=(X_train.shape[1],))\n",
        "\n",
        "# Define the encoder\n",
        "# encoded = Dense(32, activation='relu')(input_data)\n",
        "encoded = Dense(16, activation='relu')(input_data)\n",
        "encoded = Dense(8, activation='relu')(encoded)\n",
        "encoded = Dense(2, activation='relu')(encoded)\n",
        "\n",
        "encoder = Model(input_data, encoded, name='encoded')\n",
        "encoder.summary()\n",
        "\n",
        "# Define the decoder\n",
        "# decoder takes the latenet space variables\n",
        "decoded = Dense(8, activation='relu')(encoded)\n",
        "decoded = Dense(16, activation='relu')(decoded)\n",
        "# decoded = Dense(32, activation='relu')(decoded)\n",
        "decoded = Dense(9, activation='linear')(decoded)\n",
        "\n",
        "decoder = Model(encoded, decoded, name='decoded')\n",
        "decoder.summary()\n",
        "\n",
        "# define the autoEncoder\n",
        "\n",
        "rec = decoder(encoder(input_data))\n",
        "autoencoder = Model(input_data,rec)\n",
        "reconstruction_loss = tf.keras.losses.MeanSquaredError()(input_data, rec)\n",
        "autoencoder.add_loss(reconstruction_loss)\n",
        "autoencoder.compile(optimizer='adam')\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKsjrk6MSdEz",
        "outputId": "ed3a5af5-e35b-4bfe-d93b-46cf7bd3622e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoded\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 9)]               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                160       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 314\n",
            "Trainable params: 314\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoded\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 24        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                144       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 9)                 153       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 9)]          0           []                               \n",
            "                                                                                                  \n",
            " encoded (Functional)           (None, 2)            314         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " decoded (Functional)           (None, 9)            321         ['encoded[0][0]']                \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor (TFOpLamb  (None, 9)           0           ['decoded[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.cast (TFOpLambda)           (None, 9)            0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.squared_difference (TF  (None, 9)           0           ['tf.convert_to_tensor[0][0]',   \n",
            " OpLambda)                                                        'tf.cast[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpLambd  (None,)             0           ['tf.math.squared_difference[0][0\n",
            " a)                                                              ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None,)              0           ['tf.math.reduce_mean[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum (TFOpLambda  ()                  0           ['tf.math.multiply[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.compat.v1.size (TFOpLambda)  ()                  0           ['tf.math.multiply[0][0]']       \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_1 (TFOpLamb  ()                  0           ['tf.math.reduce_sum[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.cast_1 (TFOpLambda)         ()                   0           ['tf.compat.v1.size[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.divide_no_nan (TFOpLam  ()                  0           ['tf.math.reduce_sum_1[0][0]',   \n",
            " bda)                                                             'tf.cast_1[0][0]']              \n",
            "                                                                                                  \n",
            " add_loss (AddLoss)             ()                   0           ['tf.math.divide_no_nan[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 635\n",
            "Trainable params: 635\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model, this can take some time\n",
        "history = autoencoder.fit(X_train, X_train,\n",
        "                epochs=100,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, X_test))\n",
        "autoencoder.save_weights('ae_etivity_1.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5dbHelVdbh7",
        "outputId": "c85cb58e-4854-4fab-b34d-8a6583559f30"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "307/307 [==============================] - 2s 4ms/step - loss: 0.1564 - val_loss: 0.0753\n",
            "Epoch 2/100\n",
            "307/307 [==============================] - 1s 4ms/step - loss: 0.0398 - val_loss: 0.0171\n",
            "Epoch 3/100\n",
            "307/307 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0053\n",
            "Epoch 4/100\n",
            "307/307 [==============================] - 1s 5ms/step - loss: 0.0043 - val_loss: 0.0038\n",
            "Epoch 5/100\n",
            "307/307 [==============================] - 2s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 6/100\n",
            "307/307 [==============================] - 2s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 7/100\n",
            "307/307 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 8/100\n",
            "307/307 [==============================] - 2s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 9/100\n",
            "307/307 [==============================] - 2s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 10/100\n",
            "307/307 [==============================] - 2s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 11/100\n",
            "307/307 [==============================] - 1s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 12/100\n",
            "307/307 [==============================] - 1s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 13/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 14/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 15/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 16/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 17/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 18/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 19/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 20/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 21/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 22/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 23/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 24/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 25/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 26/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 27/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 28/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 29/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 30/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 31/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 32/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 33/100\n",
            "307/307 [==============================] - 1s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 34/100\n",
            "307/307 [==============================] - 1s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 35/100\n",
            "307/307 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 36/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 37/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 38/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 39/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 40/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 41/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 42/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 43/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 44/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 45/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 46/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 47/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 48/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 49/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 50/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 51/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 52/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 53/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 54/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 55/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 56/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 57/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 58/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 59/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 60/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 61/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 62/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 63/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 64/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 65/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 66/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 67/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 68/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 69/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 70/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 71/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 72/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 73/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 74/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 75/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 76/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 77/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 78/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 79/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 80/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 81/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 82/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 83/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 84/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 85/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 86/100\n",
            "307/307 [==============================] - 1s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 87/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 88/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 89/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 90/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 91/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 92/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 93/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 94/100\n",
            "307/307 [==============================] - 1s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 95/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 96/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 97/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 98/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 99/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
            "Epoch 100/100\n",
            "307/307 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fBWB78jH-3E"
      },
      "source": [
        "**Task 3: anomaly detection**\n",
        "\n",
        "From the histogram of the reconstruction error decide what the cutoff should be applied to distinguish anomalies from valid samples, given that the anomaly rate is ~7%."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# calculate predictions from our AutoEncoder model for the training dataset\n",
        "predictions = autoencoder.predict(X_test)\n",
        "\n",
        "# calculate the mean squared error for each sample\n",
        "mse = ((X_test - predictions) ** 2).mean(axis=1)\n",
        "\n",
        "# plot the histogram of mse\n",
        "n, bins, patches = plt.hist(mse, bins=100)\n",
        "\n",
        "# sort the mse in descending order\n",
        "mse_sorted = sorted(mse, reverse=True)\n",
        "\n",
        "# calculate the index of the threshold value\n",
        "threshold_index = int(len(mse_sorted) * 0.07)\n",
        "\n",
        "# set the threshold to the value at the threshold index\n",
        "threshold = mse_sorted[threshold_index]\n",
        "print(f'threshold is {threshold}')\n",
        "\n",
        "# add a vertical line to the plot at the threshold value\n",
        "plt.vlines(threshold, 0, n.max(), colors='r', linewidth=2)\n",
        "\n",
        "# identify the samples that have a mse greater than the threshold \n",
        "anomalies = X_test[mse > threshold]\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "3qyTPk17giFO",
        "outputId": "5f7aa610-11fc-4ba6-be69-2b778488dff0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "307/307 [==============================] - 0s 1ms/step\n",
            "threshold is 0.009999039159472051\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUwElEQVR4nO3df4xd5X3n8fenNj+ySTeYMEXE9q7d1t0KqoQgB1ilWmVBAQOrmnbTiHQ3WCwrd7UgJVJ/xKQrkR9FIlVbtpESKre4MVW3DqWNsMBb1iFU2aw2wECIg6EsEyCLvQQmmJBSVLqm3/3jPmbvMR77ztw7d2bw+yVd3XO+5znnPI9nNB+fH/eeVBWSJB3yIwvdAUnS4mIwSJI6DAZJUofBIEnqMBgkSR3LF7oDR3PaaafVmjVrFrobkrSkPPjgg9+vqom5rr+og2HNmjVMTk4udDckaUlJ8t1h1vdUkiSpw2CQJHUYDJKkDoNBktRhMEiSOgwGSVKHwSBJ6jAYJEkdBoMkqWNRf/J5WGu23PX69NM3Xja+HSe9dx+CJGkJ8ohBktRhMEiSOgwGSVKHwSBJ6jAYJEkdBoMkqcNgkCR1DBwMSZYl+WaSO9v82iT3JZlK8qUkJ7b6SW1+qi1f07eN61r98SQXj3owkqThzeaI4aPAY33znwVuqqqfBF4Erm71q4EXW/2m1o4kZwJXAGcBG4AvJFk2XPclSaM2UDAkWQVcBvxhmw9wAXB7a7IduLxNb2zztOUXtvYbgR1V9WpVPQVMAeeOYhCSpNEZ9IjhPwO/DvxDm38H8IOqOtjm9wEr2/RK4BmAtvyl1v71+hHWeV2SzUkmk0xOT0/PYiiSpFE4ZjAk+VfA81X14Bj6Q1Vtrar1VbV+YmJiHLuUJPUZ5Ev03gf8XJJLgZOBfwz8HnBKkuXtqGAVsL+13w+sBvYlWQ68HXihr35I/zqSpEXimEcMVXVdVa2qqjX0Lh5/tar+DXAv8MHWbBNwR5ve2eZpy79aVdXqV7S7ltYC64D7RzYSSdJIDPO12x8HdiT5TeCbwC2tfgvwx0mmgAP0woSq2pvkNuBR4CBwTVW9NsT+JUnzYFbBUFV/BfxVm36SI9xVVFV/B/ziDOvfANww205KksbHTz5LkjoMBklSh8EgSeowGCRJHQaDJKnDYJAkdRgMkqQOg0GS1GEwSJI6DAZJUofBIEnqMBgkSR0GgySpw2CQJHUYDJKkjkGe+XxykvuTfCvJ3iSfavUvJnkqycPtdXarJ8nnkkwl2ZPknL5tbUryRHttmmmfkqSFM8iDel4FLqiql5OcAHw9yX9ty36tqm4/rP0l9B7buQ44D7gZOC/JqcD1wHqggAeT7KyqF0cxEEnSaAzyzOeqqpfb7AntVUdZZSNwa1vvG8ApSc4ALgZ2V9WBFga7gQ3DdV+SNGoDXWNIsizJw8Dz9P6439cW3dBOF92U5KRWWwk807f6vlabqX74vjYnmUwyOT09PcvhSJKGNVAwVNVrVXU2sAo4N8nPANcBPw28FzgV+PgoOlRVW6tqfVWtn5iYGMUmJUmzMKu7kqrqB8C9wIaqeradLnoV+CPg3NZsP7C6b7VVrTZTXZK0iAxyV9JEklPa9FuADwB/3a4bkCTA5cAjbZWdwJXt7qTzgZeq6lngbuCiJCuSrAAuajVJ0iIyyF1JZwDbkyyjFyS3VdWdSb6aZAII8DDwH1r7XcClwBTwCnAVQFUdSPIZ4IHW7tNVdWB0Q5EkjcIxg6Gq9gDvOUL9ghnaF3DNDMu2Adtm2UdJ0hj5yWdJUofBIEnqMBgkSR0GgySpw2CQJHUYDJKkDoNBktRhMEiSOgwGSVKHwSBJ6jAYJEkdBoMkqcNgkCR1GAySpA6DQZLUYTBIkjoGebTnyUnuT/KtJHuTfKrV1ya5L8lUki8lObHVT2rzU235mr5tXdfqjye5eL4GJUmau0GOGF4FLqiqdwNnAxvas5w/C9xUVT8JvAhc3dpfDbzY6je1diQ5E7gCOAvYAHyhPS5UkrSIHDMYquflNntCexVwAXB7q28HLm/TG9s8bfmFSdLqO6rq1ap6it4zoc8dySgGsGbLXa+/JEkzG+gaQ5JlSR4Gngd2A98BflBVB1uTfcDKNr0SeAagLX8JeEd//Qjr9O9rc5LJJJPT09OzH5EkaSgDBUNVvVZVZwOr6P0v/6fnq0NVtbWq1lfV+omJifnajSRpBrO6K6mqfgDcC/xz4JQky9uiVcD+Nr0fWA3Qlr8deKG/foR1JEmLxCB3JU0kOaVNvwX4APAYvYD4YGu2CbijTe9s87TlX62qavUr2l1La4F1wP2jGogkaTSWH7sJZwDb2x1EPwLcVlV3JnkU2JHkN4FvAre09rcAf5xkCjhA704kqmpvktuAR4GDwDVV9dpohyNJGtYxg6Gq9gDvOUL9SY5wV1FV/R3wizNs6wbghtl3U5I0Ln7yWZLUYTBIkjoMBklSh8EgSeowGCRJHQaDJKnDYJAkdRgMkqQOg0GS1GEwSJI6DAZJUofBIEnqMBgkSR0GgySpw2CQJHUM8gS31UnuTfJokr1JPtrqn0yyP8nD7XVp3zrXJZlK8niSi/vqG1ptKsmW+RmSJGkYgzzB7SDwK1X1UJIfBR5Msrstu6mqfru/cZIz6T217SzgncBXkvxUW/x5eo8G3Qc8kGRnVT06ioFIkkZjkCe4PQs826b/JsljwMqjrLIR2FFVrwJPtUd8HnrS21R78htJdrS2BoMkLSKzusaQZA29x3ze10rXJtmTZFuSFa22Enimb7V9rTZT/fB9bE4ymWRyenp6Nt2TJI3AwMGQ5G3AnwMfq6ofAjcDPwGcTe+I4ndG0aGq2lpV66tq/cTExCg2KUmahUGuMZDkBHqh8CdV9RcAVfVc3/I/AO5ss/uB1X2rr2o1jlKXJC0Sg9yVFOAW4LGq+t2++hl9zX4eeKRN7wSuSHJSkrXAOuB+4AFgXZK1SU6kd4F652iGIUkalUGOGN4HfAT4dpKHW+0TwIeTnA0U8DTwywBVtTfJbfQuKh8Erqmq1wCSXAvcDSwDtlXV3hGORZI0AoPclfR1IEdYtOso69wA3HCE+q6jrSdJWnh+8lmS1GEwSJI6DAZJUofBIEnqMBgkSR0GgySpw2CQJHUYDJKkDoNBktRhMEiSOgwGSVKHwSBJ6jAYJEkdBoMkqcNgkCR1GAySpI5BHu25Osm9SR5NsjfJR1v91CS7kzzR3le0epJ8LslUkj1Jzunb1qbW/okkm+ZvWJKkuRrkiOEg8CtVdSZwPnBNkjOBLcA9VbUOuKfNA1xC7znP64DNwM3QCxLgeuA84Fzg+kNhIklaPI4ZDFX1bFU91Kb/BngMWAlsBLa3ZtuBy9v0RuDW6vkGcEqSM4CLgd1VdaCqXgR2AxtGOhpJ0tBmdY0hyRrgPcB9wOlV9Wxb9D3g9Da9Enimb7V9rTZT/fB9bE4ymWRyenp6Nt2TJI3AwMGQ5G3AnwMfq6of9i+rqgJqFB2qqq1Vtb6q1k9MTIxik5KkWRgoGJKcQC8U/qSq/qKVn2uniGjvz7f6fmB13+qrWm2muiRpERnkrqQAtwCPVdXv9i3aCRy6s2gTcEdf/cp2d9L5wEvtlNPdwEVJVrSLzhe1miRpEVk+QJv3AR8Bvp3k4Vb7BHAjcFuSq4HvAh9qy3YBlwJTwCvAVQBVdSDJZ4AHWrtPV9WBkYxCkjQyxwyGqvo6kBkWX3iE9gVcM8O2tgHbZtNBSdJ4+clnSVKHwSBJ6jAYJEkdBoMkqcNgkCR1GAySpA6DQZLUYTBIkjoMBklSh8EgSeowGCRJHQaDJKnDYJAkdRgMkqQOg0GS1DHIE9y2JXk+ySN9tU8m2Z/k4fa6tG/ZdUmmkjye5OK++oZWm0qyZfRDkSSNwiBHDF8ENhyhflNVnd1euwCSnAlcAZzV1vlCkmVJlgGfBy4BzgQ+3NpKkhaZQZ7g9rUkawbc3kZgR1W9CjyVZAo4ty2bqqonAZLsaG0fnXWPJUnzaphrDNcm2dNONa1otZXAM31t9rXaTPU3SLI5yWSSyenp6SG6J0mai7kGw83ATwBnA88CvzOqDlXV1qpaX1XrJyYmRrVZSdKAjnkq6Uiq6rlD00n+ALizze4HVvc1XdVqHKUuSVpE5nTEkOSMvtmfBw7dsbQTuCLJSUnWAuuA+4EHgHVJ1iY5kd4F6p1z77Ykab4c84ghyZ8C7wdOS7IPuB54f5KzgQKeBn4ZoKr2JrmN3kXlg8A1VfVa2861wN3AMmBbVe0d+WgkSUMb5K6kDx+hfMtR2t8A3HCE+i5g16x6J0kaOz/5LEnqMBgkSR0GgySpw2CQJHUYDJKkDoNBktRhMEiSOgwGSVKHwSBJ6jAYJEkdBoMkqcNgkCR1GAySpA6DQZLUYTBIkjoMBklSxzGDIcm2JM8neaSvdmqS3UmeaO8rWj1JPpdkKsmeJOf0rbOptX8iyab5GY4kaViDHDF8EdhwWG0LcE9VrQPuafMAl9B7zvM6YDNwM/SChN4jQc8DzgWuPxQmkqTF5ZjBUFVfAw4cVt4IbG/T24HL++q3Vs83gFOSnAFcDOyuqgNV9SKwmzeGjSRpEZjrNYbTq+rZNv094PQ2vRJ4pq/dvlabqf4GSTYnmUwyOT09PcfuSZLmauiLz1VVQI2gL4e2t7Wq1lfV+omJiVFtVpI0oLkGw3PtFBHt/flW3w+s7mu3qtVmqkuSFpm5BsNO4NCdRZuAO/rqV7a7k84HXmqnnO4GLkqyol10vqjVJEmLzPJjNUjyp8D7gdOS7KN3d9GNwG1Jrga+C3yoNd8FXApMAa8AVwFU1YEknwEeaO0+XVWHX9CWJC0CxwyGqvrwDIsuPELbAq6ZYTvbgG2z6p0kaez85LMkqcNgkCR1GAySpA6DQZLUYTBIkjoMBklSh8EgSeowGCRJHQaDJKnjmJ98fjNas+Wu16efvvGyBeyJJC0+HjFIkjoMBklSh8EgSeowGCRJHQaDJKljqGBI8nSSbyd5OMlkq52aZHeSJ9r7ilZPks8lmUqyJ8k5oxiAJGm0RnHE8C+r6uyqWt/mtwD3VNU64J42D3AJsK69NgM3j2DfkqQRm49TSRuB7W16O3B5X/3W6vkGcEqSM+Zh/5KkIQwbDAX8tyQPJtncaqdX1bNt+nvA6W16JfBM37r7Wq0jyeYkk0kmp6enh+yeJGm2hv3k889W1f4kPwbsTvLX/QurqpLUbDZYVVuBrQDr16+f1bqSpOENdcRQVfvb+/PAl4FzgecOnSJq78+35vuB1X2rr2o1SdIiMudgSPLWJD96aBq4CHgE2Alsas02AXe06Z3Ale3upPOBl/pOOUmSFolhTiWdDnw5yaHt/Jeq+sskDwC3Jbka+C7wodZ+F3ApMAW8Alw1xL4lSfNkzsFQVU8C7z5C/QXgwiPUC7hmrvuTJI2Hn3yWJHUYDJKkDoNBktRhMEiSOgwGSVKHwSBJ6jAYJEkdw35X0pvKmi13vT799I2XLWBPJGnhHPfB0B8GkiRPJUmSDnPcHzEMw1NPkt6MDIZZ8tSTpDc7g2FEOkcPC9eNgXikI+loDIYZHC9HBoaEpMMZDHqdISEJvCtJknSYsR8xJNkA/B6wDPjDqrpx3H04Hh0vp8YkDW+swZBkGfB54APAPuCBJDur6tFx9mNc1my5y1Myi9wgp89mauOpN71ZjfuI4Vxgqj0WlCQ7gI3AmzIYlrKZjjCW6h/AYQJgmO0bHlqK0nsU85h2lnwQ2FBV/77NfwQ4r6qu7WuzGdjcZv8Z8Pgcd3ca8P0hurvUHc/jP57HDo7/eB7/obH/06qamOtGFt1dSVW1Fdg67HaSTFbV+hF0aUk6nsd/PI8dHP/xPP5RjX3cdyXtB1b3za9qNUnSIjHuYHgAWJdkbZITgSuAnWPugyTpKMZ6KqmqDia5Frib3u2q26pq7zztbujTUUvc8Tz+43ns4PiP5/GPZOxjvfgsSVr8/OSzJKnDYJAkdSzJYEiyIcnjSaaSbDnC8pOSfKktvy/Jmr5l17X640kuHme/R2Wu40/ygSQPJvl2e79g3H0f1jA/+7b8nyR5OcmvjqvPozTk7/67kvzPJHvb78DJ4+z7sIb4vT8hyfY25seSXDfuvo/CAOP/F0keSnKwfWasf9mmJE+016Zj7qyqltSL3kXr7wA/DpwIfAs487A2/xH4/TZ9BfClNn1ma38SsLZtZ9lCj2mM438P8M42/TPA/oUez7jG3rf8duDPgF9d6PGM+We/HNgDvLvNv2Mp/e4POfZfAna06X9E75EpaxZ6TPMw/jXAu4BbgQ/21U8FnmzvK9r0iqPtbykeMbz+tRpV9ffAoa/V6LcR2N6mbwcuTJJW31FVr1bVU8BU295SMufxV9U3q+r/tPpe4C1JThpLr0djmJ89SS4HnqI39qVomPFfBOypqm8BVNULVfXamPo9CsOMvYC3JlkOvAX4e+CH4+n2yBxz/FX1dFXtAf7hsHUvBnZX1YGqehHYDWw42s6WYjCsBJ7pm9/XakdsU1UHgZfo/Q9pkHUXu2HG3+9fAw9V1avz1M/5MOexJ3kb8HHgU2Po53wZ5mf/U0Alubudbvj1MfR3lIYZ++3A3wLPAv8b+O2qOjDfHR6xYf52zXrdRfeVGJp/Sc4CPkvvf5HHi08CN1XVy+0A4nizHPhZ4L3AK8A9SR6sqnsWtltjcS7wGvBOeqdS/nuSr1T7Mk+90VI8YhjkazVeb9MOH98OvDDguovdMOMnySrgy8CVVfWdee/taA0z9vOA30ryNPAx4BPtw5ZLyTDj3wd8raq+X1WvALuAc+a9x6MzzNh/CfjLqvq/VfU88D+ApfZdSsP87Zr9ugt9UWUOF2GW07t4spb/fxHmrMPaXEP3ItRtbfosuhefn2QJXYAbwfhPae1/YaHHMe6xH9bmkyzNi8/D/OxXAA/Ru/i6HPgKcNlCj2lMY/848Edt+q30vub/XQs9plGPv6/tF3njxeen2u/AijZ96lH3t9ADnuM/0qXA/6J3lf43Wu3TwM+16ZPp3XkyBdwP/Hjfur/R1nscuGShxzLO8QP/id651of7Xj+20OMZ18++bxtLMhiGHT/wb+ldeH8E+K2FHsu4xg68rdX3tlD4tYUeyzyN/730jgz/lt6R0t6+df9d+3eZAq461r78SgxJUsdSvMYgSZpHBoMkqcNgkCR1GAySpA6DQZLUYTBIkjoMBklSx/8DJ04pATWTT8cAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.show()"
      ],
      "metadata": {
        "id": "Ynsxq5GuvH3l"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j5hiuoF2vH0v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvfG79OoH-3F"
      },
      "source": [
        "### Post (complete by Monday 30/01/23)\n",
        "\n",
        "Post your solution to Tasks 1-3 in notebook form. If you have not completed all the tasks then that is acceptable. The purpose is to get feedback from others in the group, so if you have only a basic outline then you may get ideas about how to proceed and also examples from others in your group.\n",
        "\n",
        "No posts should refer to Task 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HW2ynAjH-3G"
      },
      "source": [
        "### Respond (complete by Wednesday 01/02/23)\n",
        "\n",
        "If you feel you can provide useful advise then respond to another member of the group through the appropriate forum. Responses should be respectful and offer some sort of advise. Try and avoid clogging the forums with support or thank you messages.\n",
        "\n",
        "In reviewing others code you will discover different ways to tackle the same problem. It is acceptable to copy parts of others code. However whole scale copying from another notebook is not acceptable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yFawJOsH-3H"
      },
      "source": [
        "Grading guidelines for the forum posts: Weight [2/7]\n",
        "\n",
        "**Beginning [0-8]:** Respectful posts of minor value. Significant number of posts without valuable contributions and/or without well-considered questions. Posts about task 4 in contravention of intructions.\n",
        "\n",
        "**Developing [9-12]:** At least 1 post  exceeding Beginning level with respectful suggestion or thought provoking question. Most posts contain valuable contributions or well-considered questions.\n",
        "\n",
        "**Advancing [13-16]:** At least 2 posts: 1 equal to or exceeding Beginning level;  1 with respectful and sound contribution highlighting mistakes or alternative approaches.\n",
        "\n",
        "**Accomplished [17-20]:** At least 3 posts: 2 equal to or exceeding Accomplished level; 1 with respectful contribution of significant value. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91SS2yODH-3I"
      },
      "source": [
        "### Task 4: VAE (completed by Sunday 05/02/23)\n",
        "\n",
        "This task is a individual task and should **not** to be uploaded to GitHub. No direct support should be given via the forums, although comments about progress or results are allowed. Marks will be deducted if the instructions are not followed (see rubrics). This part should be uploaded directly to Sulis.\n",
        "\n",
        "Change the network to be a VAE. Again determine the optimal cutoff and plot the latent variables. Check how good the cutoffs were by constructing a confusion matrix or generating a classification report. Obviously for this task you need to use the Anom column.\n",
        "\n",
        "**Hint** you can use the model topology from the AE (with the obvious modifications). I found that I had a good model (almost as good and the supervised learning model) when the KL divergence was small. You can print out both the KL divergence and reconstruction loss for each epoch. It can be tricky to train these type of models, so do not be surprised if you do not get a stellar result. What is more important is that you have the correct code to implement the VAE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhdvKN-pH-3J"
      },
      "source": [
        "### Final Submission (complete by Sunday 05/02/23)\n",
        "\n",
        "Submit Tasks 1-4 in a single notebook this before the deadline on Sunday.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-caE6YrFH-3K"
      },
      "outputs": [],
      "source": [
        "## Add additional code cells to implememt the tasks stated above "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBIyen00H-3M"
      },
      "source": [
        "## Reflection\n",
        "\n",
        "There are no specific marks allocated for a reflection. However due consideration will be given if pertinent comments or valuable insights are made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T0DjkbrsH-3N"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}